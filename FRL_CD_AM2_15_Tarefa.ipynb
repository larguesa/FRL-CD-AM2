{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAw64TQd3uaIptsbOOS+UC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larguesa/FRL-CD-AM2/blob/main/FRL_CD_AM2_15_Tarefa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 15 de Aprendizagem de Máquinas II - Faculdade de Tecnologia de Santos\n",
        "## Busca Semântica com RAG (Retrieval-Augmented Generation)\n",
        "\n",
        "Este notebook demonstra como usar a API do Gemini para realizar buscas semânticas com dados de uma empresa fictícia, \"NexusTech\". Vamos:\n",
        "\n",
        "1. Criar uma lista de 10 perguntas e respostas sobre uma empresa fictícia\n",
        "2. Gerar embeddings para as respostas usando a API do Gemini e armazená-los em memória.\n",
        "3. Implementar uma função de busca semântica para encontrar pares pergunta-resposta relevantes com base em uma query.\n",
        "4. Gerar respostas para queries de exemplo usando o contexto recuperado.\n",
        "\n",
        "**Pré-requisitos:**\n",
        "- Uma chave de API do Gemini (inclua sua chave no secrets do Colab no ícone da chave do menu lateral esquerdo).\n",
        "- Instalar as dependências necessárias."
      ],
      "metadata": {
        "id": "NjLw-6_biu_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 1: Instalação e importação de bibliotecas\n",
        "!pip install -q google-generativeai sklearn numpy\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import textwrap\n",
        "\n",
        "# Função auxiliar para formatar markdown (opcional, para melhor visualização)\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "print(\"Bibliotecas instaladas e importadas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3-7xdhfqLtz",
        "outputId": "589dbc2f-00de-400f-a7eb-34c8038ac1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Bibliotecas instaladas e importadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2: Configuração da API Key do Gemini\n",
        "# NOTA: Vá em \"Secrets\" (ícone de chave no menu à esquerda do Colab)\n",
        "# e adicione sua API Key com o nome \"GOOGLE_API_KEY\".\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"API Key do Gemini configurada com sucesso!\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Erro: Chave 'GOOGLE_API_KEY' não encontrada nos Secrets do Colab.\")\n",
        "    print(\"Por favor, adicione sua API Key do Gemini nos Secrets com o nome 'GOOGLE_API_KEY'.\")\n",
        "    # Você pode adicionar um input manual como fallback se preferir, mas Secrets é mais seguro:\n",
        "    # GOOGLE_API_KEY = input(\"Cole sua API Key do Gemini aqui: \")\n",
        "    # genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao configurar a API Key: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a37V38QQqVxy",
        "outputId": "c1586709-aa7a-448e-e9ef-48da2525184d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key do Gemini configurada com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 3: Definição dos dados da empresa fictícia (Perguntas e Respostas)\n",
        "\n",
        "dados_empresa_ficticia = [\n",
        "    {\n",
        "        \"id\": \"qa_01\",\n",
        "        \"pergunta\": \"Qual o nome da empresa?\",\n",
        "        \"resposta\": \"O nome da empresa é NexusTech Soluções Inovadoras.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"qa_02\",\n",
        "        \"pergunta\": \"Quando a NexusTech foi fundada?\",\n",
        "        \"resposta\": \"A NexusTech foi fundada em 15 de março de 2010.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"qa_03\",\n",
        "        \"pergunta\": \"Quem são os fundadores da NexusTech?\",\n",
        "        \"resposta\": \"Os fundadores da NexusTech são Ana Silva (CEO), Bruno Costa (CTO) e Carla Dias (COO).\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"qa_04\",\n",
        "        \"pergunta\": \"Quantos funcionários a NexusTech possui atualmente?\",\n",
        "        \"resposta\": \"A NexusTech possui atualmente cerca de 150 funcionários.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"qa_05\",\n",
        "        \"pergunta\": \"Qual é o principal serviço de desenvolvimento oferecido pela NexusTech?\",\n",
        "        \"resposta\": \"O principal serviço de desenvolvimento da NexusTech é o desenvolvimento de software sob medida para as necessidades específicas de cada cliente.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"qa_06\",\n",
        "        \"pergunta\": \"A NexusTech oferece serviços de consultoria?\",\n",
        "        \"resposta\": \"Sim, a NexusTech oferece consultoria especializada em transformação digital para empresas de diversos portes.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"qa_07\",\n",
        "        \"pergunta\": \"Como funciona o suporte técnico da NexusTech?\",\n",
        "        \"resposta\": \"A NexusTech oferece suporte técnico especializado 24 horas por dia, 7 dias por semana, para garantir a continuidade das operações de seus clientes.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"qa_08\",\n",
        "        \"pergunta\": \"Qual é a missão da NexusTech?\",\n",
        "        \"resposta\": \"A missão da NexusTech é empoderar negócios através de tecnologia de ponta e soluções personalizadas.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"qa_09\",\n",
        "        \"pergunta\": \"Qual a visão de futuro da NexusTech?\",\n",
        "        \"resposta\": \"A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"qa_10\",\n",
        "        \"pergunta\": \"Quais são os principais valores da NexusTech?\",\n",
        "        \"resposta\": \"Os principais valores da NexusTech são: Inovação contínua, Colaboração entre equipes e com clientes, foco no Cliente no Centro de todas as decisões, Integridade em todas as ações e busca incessante pela Excelência.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Combinar pergunta e resposta para vetorização\n",
        "textos_para_vetorizar = [f\"Pergunta: {item['pergunta']} Resposta: {item['resposta']}\" for item in dados_empresa_ficticia]\n",
        "\n",
        "print(f\"{len(textos_para_vetorizar)} Q&As definidos para a NexusTech Soluções Inovadoras.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMkYXrYxqkDn",
        "outputId": "e3539aae-b7ac-4026-d270-634e6885745f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Q&As definidos para a NexusTech Soluções Inovadoras.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 4: Vetorização dos dados (Q&A) usando a API do Gemini\n",
        "\n",
        "# Modelo de embedding\n",
        "embedding_model = 'models/embedding-001' # Modelo mais recente pode ser text-embedding-004\n",
        "\n",
        "embeddings_list = []\n",
        "print(\"Iniciando vetorização dos Q&As...\")\n",
        "try:\n",
        "    for i, texto in enumerate(textos_para_vetorizar):\n",
        "        print(f\"Vetorizando Q&A {i+1}/{len(textos_para_vetorizar)}...\")\n",
        "        # O retry automático já está embutido na biblioteca Python a partir de certas versões\n",
        "        # Se encontrar erros de quota, pode ser necessário adicionar um time.sleep()\n",
        "        response = genai.embed_content(model=embedding_model,\n",
        "                                       content=texto,\n",
        "                                       task_type=\"RETRIEVAL_DOCUMENT\") # ou \"SEMANTIC_SIMILARITY\"\n",
        "        embeddings_list.append(response['embedding'])\n",
        "    embeddings_qa = np.array(embeddings_list)\n",
        "    print(f\"Vetorização concluída! Dimensão dos embeddings: {embeddings_qa.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro durante a vetorização: {e}\")\n",
        "    print(\"Verifique sua API Key, cotas e o modelo de embedding especificado.\")\n",
        "    embeddings_qa = None # Define como None para evitar erros subsequentes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "g_-I21RYqopF",
        "outputId": "64dfa211-8403-4f34-8347-d0d2020f0297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando vetorização dos Q&As...\n",
            "Vetorizando Q&A 1/10...\n",
            "Vetorizando Q&A 2/10...\n",
            "Vetorizando Q&A 3/10...\n",
            "Vetorizando Q&A 4/10...\n",
            "Vetorizando Q&A 5/10...\n",
            "Vetorizando Q&A 6/10...\n",
            "Vetorizando Q&A 7/10...\n",
            "Vetorizando Q&A 8/10...\n",
            "Vetorizando Q&A 9/10...\n",
            "Vetorizando Q&A 10/10...\n",
            "Vetorização concluída! Dimensão dos embeddings: (10, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5: Função para busca por similaridade semântica\n",
        "\n",
        "def buscar_contextos_similares(pergunta_usuario, embeddings_base, textos_base, top_n=2):\n",
        "    if embeddings_base is None or len(embeddings_base) == 0:\n",
        "        print(\"Embeddings base não estão disponíveis.\")\n",
        "        return [], []\n",
        "\n",
        "    print(f\"\\nBuscando contextos para a pergunta: '{pergunta_usuario}'\")\n",
        "    # Vetorizar a pergunta do usuário\n",
        "    try:\n",
        "        embedding_pergunta = genai.embed_content(model=embedding_model,\n",
        "                                                 content=pergunta_usuario,\n",
        "                                                 task_type=\"RETRIEVAL_QUERY\")['embedding'] # ou \"SEMANTIC_SIMILARITY\"\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao vetorizar a pergunta do usuário: {e}\")\n",
        "        return [], []\n",
        "\n",
        "    embedding_pergunta_np = np.array(embedding_pergunta).reshape(1, -1)\n",
        "\n",
        "    # Calcular similaridade de cosseno\n",
        "    similaridades = cosine_similarity(embedding_pergunta_np, embeddings_base)\n",
        "\n",
        "    # Obter os índices dos top_n mais similares\n",
        "    # argsort retorna os índices que ordenariam o array. Pegamos os últimos N.\n",
        "    indices_similares = similaridades[0].argsort()[-top_n:][::-1] # Do mais similar para o menos\n",
        "\n",
        "    contextos_encontrados_texto = [textos_base[i] for i in indices_similares]\n",
        "    ids_contextos_originais = [dados_empresa_ficticia[i]['id'] for i in indices_similares]\n",
        "\n",
        "    print(f\"Top {top_n} contextos encontrados (IDs): {ids_contextos_originais}\")\n",
        "    return contextos_encontrados_texto, ids_contextos_originais"
      ],
      "metadata": {
        "id": "T4ICYVgQqsho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 6: Função para gerar resposta usando o Gemini com contexto\n",
        "\n",
        "# Modelo generativo\n",
        "generation_model = genai.GenerativeModel('gemini-1.5-flash-latest') # ou 'gemini-pro'\n",
        "\n",
        "def gerar_resposta_com_contexto(pergunta_usuario, contextos):\n",
        "    if not contextos:\n",
        "        prompt_final = f\"\"\"Responda à seguinte pergunta da melhor forma possível, com base no seu conhecimento geral,\n",
        "        já que nenhum contexto específico foi fornecido:\n",
        "\n",
        "        Pergunta: {pergunta_usuario}\n",
        "\n",
        "        Resposta:\n",
        "        \"\"\"\n",
        "    else:\n",
        "        contexto_formatado = \"\\n\\n\".join([f\"Contexto {i+1}:\\n{ctx}\" for i, ctx in enumerate(contextos)])\n",
        "        prompt_final = f\"\"\"Com base nos seguintes contextos:\n",
        "\n",
        "{contexto_formatado}\n",
        "\n",
        "Responda à pergunta: \"{pergunta_usuario}\"\n",
        "\n",
        "---\n",
        "Instruções Adicionais:\n",
        "- Use APENAS as informações dos contextos fornecidos para responder à pergunta.\n",
        "- Se a resposta não estiver nos contextos, diga explicitamente que a informação não foi encontrada nos documentos fornecidos.\n",
        "- Não invente informações.\n",
        "\n",
        "Resposta:\n",
        "\"\"\"\n",
        "\n",
        "    print(\"\\n--- Prompt Enviado ao Modelo Generativo ---\")\n",
        "    print(prompt_final)\n",
        "    print(\"----------------------------------------\")\n",
        "\n",
        "    try:\n",
        "        resposta_gemini = generation_model.generate_content(prompt_final)\n",
        "        return resposta_gemini.text\n",
        "    except Exception as e:\n",
        "        return f\"Erro ao gerar resposta: {e}\""
      ],
      "metadata": {
        "id": "dh5GlHi7qxIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 7: Execução dos exemplos\n",
        "\n",
        "perguntas_exemplo = [\n",
        "    \"Quem é o CEO da NexusTech?\",\n",
        "    \"Quantos funcionários a NexusTech possui atualmente?\",\n",
        "    \"O que a NexusTech faz?\",\n",
        "    \"Qual é o principal objetivo da empresa NexusTech?\",\n",
        "    \"Como a NexusTech ajuda outras empresas a se modernizarem?\",\n",
        "    \"A empresa oferece algum tipo de garantia ou acordo de nível de serviço (SLA) para o suporte técnico?\" # Pergunta que pode não estar explicitamente nos Q&As\n",
        "]\n",
        "\n",
        "if embeddings_qa is not None and GOOGLE_API_KEY: # Verifica se a vetorização e a API Key estão ok\n",
        "    for pergunta_user in perguntas_exemplo:\n",
        "        print(f\"\\n======================================================================\")\n",
        "        print(f\"PROCESSANDO PERGUNTA DO USUÁRIO: {pergunta_user}\")\n",
        "        print(f\"======================================================================\")\n",
        "\n",
        "        contextos_selecionados, ids_contextos = buscar_contextos_similares(\n",
        "            pergunta_user,\n",
        "            embeddings_qa,\n",
        "            textos_para_vetorizar,\n",
        "            top_n=2  # Você pode ajustar o número de contextos a serem recuperados\n",
        "        )\n",
        "\n",
        "        print(\"\\n--- Contextos que serão incorporados ao prompt ---\")\n",
        "        if contextos_selecionados:\n",
        "            for i, ctx_text in enumerate(contextos_selecionados):\n",
        "                # Encontrar o Q&A original correspondente para exibição mais clara\n",
        "                qa_original = next(item for item in dados_empresa_ficticia if item[\"id\"] == ids_contextos[i])\n",
        "                print(f\"ID do Q&A: {qa_original['id']}\")\n",
        "                print(f\"  P: {qa_original['pergunta']}\")\n",
        "                print(f\"  R: {qa_original['resposta']}\\n\")\n",
        "        else:\n",
        "            print(\"Nenhum contexto similar encontrado para esta pergunta.\")\n",
        "        print(\"----------------------------------------------------\")\n",
        "\n",
        "        resposta_final = gerar_resposta_com_contexto(pergunta_user, contextos_selecionados)\n",
        "\n",
        "        print(\"\\n--- Resposta Final do Gemini ---\")\n",
        "        print(textwrap.fill(resposta_final, width=100)) # Formata a largura da linha para melhor leitura\n",
        "        print(\"--------------------------------\\n\")\n",
        "        if contextos_selecionados:\n",
        "            print(f\"Contextos utilizados para esta resposta (IDs): {ids_contextos}\")\n",
        "        else:\n",
        "            print(\"Nenhum contexto específico foi utilizado.\")\n",
        "        print(\"--------------------------------\\n\")\n",
        "\n",
        "else:\n",
        "    if not GOOGLE_API_KEY:\n",
        "        print(\"A API Key do Gemini não foi configurada. Execute a Célula 2 e configure-a.\")\n",
        "    if embeddings_qa is None:\n",
        "        print(\"A vetorização dos Q&As falhou ou não foi executada. Verifique a Célula 4.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tknjZtXPqz3o",
        "outputId": "45b7376a-fa1c-401a-f8b2-0497d614fe7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PROCESSANDO PERGUNTA DO USUÁRIO: Quem é o CEO da NexusTech?\n",
            "======================================================================\n",
            "\n",
            "Buscando contextos para a pergunta: 'Quem é o CEO da NexusTech?'\n",
            "Top 2 contextos encontrados (IDs): ['qa_03', 'qa_09']\n",
            "\n",
            "--- Contextos que serão incorporados ao prompt ---\n",
            "ID do Q&A: qa_03\n",
            "  P: Quem são os fundadores da NexusTech?\n",
            "  R: Os fundadores da NexusTech são Ana Silva (CEO), Bruno Costa (CTO) e Carla Dias (COO).\n",
            "\n",
            "ID do Q&A: qa_09\n",
            "  P: Qual a visão de futuro da NexusTech?\n",
            "  R: A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\n",
            "\n",
            "----------------------------------------------------\n",
            "\n",
            "--- Prompt Enviado ao Modelo Generativo ---\n",
            "Com base nos seguintes contextos:\n",
            "\n",
            "Contexto 1:\n",
            "Pergunta: Quem são os fundadores da NexusTech? Resposta: Os fundadores da NexusTech são Ana Silva (CEO), Bruno Costa (CTO) e Carla Dias (COO).\n",
            "\n",
            "Contexto 2:\n",
            "Pergunta: Qual a visão de futuro da NexusTech? Resposta: A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\n",
            "\n",
            "Responda à pergunta: \"Quem é o CEO da NexusTech?\"\n",
            "\n",
            "---\n",
            "Instruções Adicionais:\n",
            "- Use APENAS as informações dos contextos fornecidos para responder à pergunta.\n",
            "- Se a resposta não estiver nos contextos, diga explicitamente que a informação não foi encontrada nos documentos fornecidos.\n",
            "- Não invente informações.\n",
            "\n",
            "Resposta:\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "--- Resposta Final do Gemini ---\n",
            "Ana Silva é a CEO da NexusTech.\n",
            "--------------------------------\n",
            "\n",
            "Contextos utilizados para esta resposta (IDs): ['qa_03', 'qa_09']\n",
            "--------------------------------\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PROCESSANDO PERGUNTA DO USUÁRIO: Quantos funcionários a NexusTech possui atualmente?\n",
            "======================================================================\n",
            "\n",
            "Buscando contextos para a pergunta: 'Quantos funcionários a NexusTech possui atualmente?'\n",
            "Top 2 contextos encontrados (IDs): ['qa_04', 'qa_09']\n",
            "\n",
            "--- Contextos que serão incorporados ao prompt ---\n",
            "ID do Q&A: qa_04\n",
            "  P: Quantos funcionários a NexusTech possui atualmente?\n",
            "  R: A NexusTech possui atualmente cerca de 150 funcionários.\n",
            "\n",
            "ID do Q&A: qa_09\n",
            "  P: Qual a visão de futuro da NexusTech?\n",
            "  R: A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\n",
            "\n",
            "----------------------------------------------------\n",
            "\n",
            "--- Prompt Enviado ao Modelo Generativo ---\n",
            "Com base nos seguintes contextos:\n",
            "\n",
            "Contexto 1:\n",
            "Pergunta: Quantos funcionários a NexusTech possui atualmente? Resposta: A NexusTech possui atualmente cerca de 150 funcionários.\n",
            "\n",
            "Contexto 2:\n",
            "Pergunta: Qual a visão de futuro da NexusTech? Resposta: A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\n",
            "\n",
            "Responda à pergunta: \"Quantos funcionários a NexusTech possui atualmente?\"\n",
            "\n",
            "---\n",
            "Instruções Adicionais:\n",
            "- Use APENAS as informações dos contextos fornecidos para responder à pergunta.\n",
            "- Se a resposta não estiver nos contextos, diga explicitamente que a informação não foi encontrada nos documentos fornecidos.\n",
            "- Não invente informações.\n",
            "\n",
            "Resposta:\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "--- Resposta Final do Gemini ---\n",
            "A NexusTech possui atualmente cerca de 150 funcionários.\n",
            "--------------------------------\n",
            "\n",
            "Contextos utilizados para esta resposta (IDs): ['qa_04', 'qa_09']\n",
            "--------------------------------\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PROCESSANDO PERGUNTA DO USUÁRIO: O que a NexusTech faz?\n",
            "======================================================================\n",
            "\n",
            "Buscando contextos para a pergunta: 'O que a NexusTech faz?'\n",
            "Top 2 contextos encontrados (IDs): ['qa_05', 'qa_09']\n",
            "\n",
            "--- Contextos que serão incorporados ao prompt ---\n",
            "ID do Q&A: qa_05\n",
            "  P: Qual é o principal serviço de desenvolvimento oferecido pela NexusTech?\n",
            "  R: O principal serviço de desenvolvimento da NexusTech é o desenvolvimento de software sob medida para as necessidades específicas de cada cliente.\n",
            "\n",
            "ID do Q&A: qa_09\n",
            "  P: Qual a visão de futuro da NexusTech?\n",
            "  R: A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\n",
            "\n",
            "----------------------------------------------------\n",
            "\n",
            "--- Prompt Enviado ao Modelo Generativo ---\n",
            "Com base nos seguintes contextos:\n",
            "\n",
            "Contexto 1:\n",
            "Pergunta: Qual é o principal serviço de desenvolvimento oferecido pela NexusTech? Resposta: O principal serviço de desenvolvimento da NexusTech é o desenvolvimento de software sob medida para as necessidades específicas de cada cliente.\n",
            "\n",
            "Contexto 2:\n",
            "Pergunta: Qual a visão de futuro da NexusTech? Resposta: A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\n",
            "\n",
            "Responda à pergunta: \"O que a NexusTech faz?\"\n",
            "\n",
            "---\n",
            "Instruções Adicionais:\n",
            "- Use APENAS as informações dos contextos fornecidos para responder à pergunta.\n",
            "- Se a resposta não estiver nos contextos, diga explicitamente que a informação não foi encontrada nos documentos fornecidos.\n",
            "- Não invente informações.\n",
            "\n",
            "Resposta:\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "--- Resposta Final do Gemini ---\n",
            "A NexusTech desenvolve software sob medida para as necessidades específicas de cada cliente.  Sua\n",
            "visão é ser líder global em inovação tecnológica, reconhecida pela excelência e impacto positivo.\n",
            "--------------------------------\n",
            "\n",
            "Contextos utilizados para esta resposta (IDs): ['qa_05', 'qa_09']\n",
            "--------------------------------\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PROCESSANDO PERGUNTA DO USUÁRIO: Qual é o principal objetivo da empresa NexusTech?\n",
            "======================================================================\n",
            "\n",
            "Buscando contextos para a pergunta: 'Qual é o principal objetivo da empresa NexusTech?'\n",
            "Top 2 contextos encontrados (IDs): ['qa_09', 'qa_08']\n",
            "\n",
            "--- Contextos que serão incorporados ao prompt ---\n",
            "ID do Q&A: qa_09\n",
            "  P: Qual a visão de futuro da NexusTech?\n",
            "  R: A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\n",
            "\n",
            "ID do Q&A: qa_08\n",
            "  P: Qual é a missão da NexusTech?\n",
            "  R: A missão da NexusTech é empoderar negócios através de tecnologia de ponta e soluções personalizadas.\n",
            "\n",
            "----------------------------------------------------\n",
            "\n",
            "--- Prompt Enviado ao Modelo Generativo ---\n",
            "Com base nos seguintes contextos:\n",
            "\n",
            "Contexto 1:\n",
            "Pergunta: Qual a visão de futuro da NexusTech? Resposta: A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\n",
            "\n",
            "Contexto 2:\n",
            "Pergunta: Qual é a missão da NexusTech? Resposta: A missão da NexusTech é empoderar negócios através de tecnologia de ponta e soluções personalizadas.\n",
            "\n",
            "Responda à pergunta: \"Qual é o principal objetivo da empresa NexusTech?\"\n",
            "\n",
            "---\n",
            "Instruções Adicionais:\n",
            "- Use APENAS as informações dos contextos fornecidos para responder à pergunta.\n",
            "- Se a resposta não estiver nos contextos, diga explicitamente que a informação não foi encontrada nos documentos fornecidos.\n",
            "- Não invente informações.\n",
            "\n",
            "Resposta:\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "--- Resposta Final do Gemini ---\n",
            "Com base nos contextos fornecidos, o principal objetivo da NexusTech é ser líder global em inovação\n",
            "tecnológica, empoderando negócios através de tecnologia de ponta e soluções personalizadas, com o\n",
            "intuito de gerar impacto positivo em seus clientes e na sociedade.\n",
            "--------------------------------\n",
            "\n",
            "Contextos utilizados para esta resposta (IDs): ['qa_09', 'qa_08']\n",
            "--------------------------------\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PROCESSANDO PERGUNTA DO USUÁRIO: Como a NexusTech ajuda outras empresas a se modernizarem?\n",
            "======================================================================\n",
            "\n",
            "Buscando contextos para a pergunta: 'Como a NexusTech ajuda outras empresas a se modernizarem?'\n",
            "Top 2 contextos encontrados (IDs): ['qa_09', 'qa_08']\n",
            "\n",
            "--- Contextos que serão incorporados ao prompt ---\n",
            "ID do Q&A: qa_09\n",
            "  P: Qual a visão de futuro da NexusTech?\n",
            "  R: A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\n",
            "\n",
            "ID do Q&A: qa_08\n",
            "  P: Qual é a missão da NexusTech?\n",
            "  R: A missão da NexusTech é empoderar negócios através de tecnologia de ponta e soluções personalizadas.\n",
            "\n",
            "----------------------------------------------------\n",
            "\n",
            "--- Prompt Enviado ao Modelo Generativo ---\n",
            "Com base nos seguintes contextos:\n",
            "\n",
            "Contexto 1:\n",
            "Pergunta: Qual a visão de futuro da NexusTech? Resposta: A visão da NexusTech é ser líder global em inovação tecnológica, sendo reconhecida pela excelência e pelo impacto positivo que gera em seus clientes e na sociedade.\n",
            "\n",
            "Contexto 2:\n",
            "Pergunta: Qual é a missão da NexusTech? Resposta: A missão da NexusTech é empoderar negócios através de tecnologia de ponta e soluções personalizadas.\n",
            "\n",
            "Responda à pergunta: \"Como a NexusTech ajuda outras empresas a se modernizarem?\"\n",
            "\n",
            "---\n",
            "Instruções Adicionais:\n",
            "- Use APENAS as informações dos contextos fornecidos para responder à pergunta.\n",
            "- Se a resposta não estiver nos contextos, diga explicitamente que a informação não foi encontrada nos documentos fornecidos.\n",
            "- Não invente informações.\n",
            "\n",
            "Resposta:\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "--- Resposta Final do Gemini ---\n",
            "A NexusTech ajuda outras empresas a se modernizarem através de tecnologia de ponta e soluções\n",
            "personalizadas.\n",
            "--------------------------------\n",
            "\n",
            "Contextos utilizados para esta resposta (IDs): ['qa_09', 'qa_08']\n",
            "--------------------------------\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PROCESSANDO PERGUNTA DO USUÁRIO: A empresa oferece algum tipo de garantia ou acordo de nível de serviço (SLA) para o suporte técnico?\n",
            "======================================================================\n",
            "\n",
            "Buscando contextos para a pergunta: 'A empresa oferece algum tipo de garantia ou acordo de nível de serviço (SLA) para o suporte técnico?'\n",
            "Top 2 contextos encontrados (IDs): ['qa_07', 'qa_05']\n",
            "\n",
            "--- Contextos que serão incorporados ao prompt ---\n",
            "ID do Q&A: qa_07\n",
            "  P: Como funciona o suporte técnico da NexusTech?\n",
            "  R: A NexusTech oferece suporte técnico especializado 24 horas por dia, 7 dias por semana, para garantir a continuidade das operações de seus clientes.\n",
            "\n",
            "ID do Q&A: qa_05\n",
            "  P: Qual é o principal serviço de desenvolvimento oferecido pela NexusTech?\n",
            "  R: O principal serviço de desenvolvimento da NexusTech é o desenvolvimento de software sob medida para as necessidades específicas de cada cliente.\n",
            "\n",
            "----------------------------------------------------\n",
            "\n",
            "--- Prompt Enviado ao Modelo Generativo ---\n",
            "Com base nos seguintes contextos:\n",
            "\n",
            "Contexto 1:\n",
            "Pergunta: Como funciona o suporte técnico da NexusTech? Resposta: A NexusTech oferece suporte técnico especializado 24 horas por dia, 7 dias por semana, para garantir a continuidade das operações de seus clientes.\n",
            "\n",
            "Contexto 2:\n",
            "Pergunta: Qual é o principal serviço de desenvolvimento oferecido pela NexusTech? Resposta: O principal serviço de desenvolvimento da NexusTech é o desenvolvimento de software sob medida para as necessidades específicas de cada cliente.\n",
            "\n",
            "Responda à pergunta: \"A empresa oferece algum tipo de garantia ou acordo de nível de serviço (SLA) para o suporte técnico?\"\n",
            "\n",
            "---\n",
            "Instruções Adicionais:\n",
            "- Use APENAS as informações dos contextos fornecidos para responder à pergunta.\n",
            "- Se a resposta não estiver nos contextos, diga explicitamente que a informação não foi encontrada nos documentos fornecidos.\n",
            "- Não invente informações.\n",
            "\n",
            "Resposta:\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "--- Resposta Final do Gemini ---\n",
            "A informação sobre garantias ou acordos de nível de serviço (SLA) para o suporte técnico não foi\n",
            "encontrada nos documentos fornecidos.\n",
            "--------------------------------\n",
            "\n",
            "Contextos utilizados para esta resposta (IDs): ['qa_07', 'qa_05']\n",
            "--------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Como Usar o Notebook:\n",
        "\n",
        "1.  **Adicione sua API Key do Gemini:**\n",
        "    * No menu à esquerda do Colab, clique no ícone de chave (\"Secrets\").\n",
        "    * Clique em \"+ Add a new secret\".\n",
        "    * Nomeie o segredo como `GOOGLE_API_KEY`.\n",
        "    * Cole sua API Key do Gemini no campo \"Value\".\n",
        "    * Ative o botão \"Notebook access\".\n",
        "2.  **Execute as Células:** Execute as células em ordem, uma por uma (Shift + Enter ou clicando no botão de play).\n",
        "    * A **Célula 1** instala as bibliotecas.\n",
        "    * A **Célula 2** configura sua API Key.\n",
        "    * A **Célula 3** define os dados da empresa fictícia.\n",
        "    * A **Célula 4** vetoriza esses dados usando o modelo de embedding do Gemini. Isso pode levar alguns segundos.\n",
        "    * A **Célula 5** define a função para busca semântica.\n",
        "    * A **Célula 6** define a função para gerar a resposta final com contexto.\n",
        "    * A **Célula 7** executa o processo para algumas perguntas de exemplo, mostrando os contextos selecionados e a resposta gerada.\n",
        "\n",
        "### Observações:\n",
        "\n",
        "* **Custos da API:** Lembre-se de que o uso da API do Gemini (tanto para embeddings quanto para geração de texto) pode incorrer em custos, dependendo do seu volume de uso e das cotas da sua conta.\n",
        "* **Modelos:** Usei `models/embedding-001` para embeddings e `gemini-1.5-flash-latest` para geração. Você pode experimentar outros modelos disponíveis. O `text-embedding-004` é uma opção mais recente para embeddings.\n",
        "* **Similaridade:** A busca por similaridade aqui usa a similaridade de cosseno, que é uma métrica comum para comparar embeddings.\n",
        "* **Número de Contextos (`top_n`):** Você pode ajustar o parâmetro `top_n` na função `buscar_contextos_similares` para controlar quantos dos Q&As mais relevantes são passados como contexto para o modelo generativo."
      ],
      "metadata": {
        "id": "DYKDDh2Lq9hv"
      }
    }
  ]
}